{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61b39779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "from nltk.corpus import webtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "603bcaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\zhuko\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zhuko\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package webtext to\n",
      "[nltk_data]     C:\\Users\\zhuko\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\webtext.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('webtext')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84805d08",
   "metadata": {},
   "source": [
    "Немного теории:\n",
    "\n",
    "В модели MLE (Maximum Likelihood Estimation) из библиотеки NLTK генерация следующего слова происходит на основе вероятности каждого слова в контексте.\n",
    "\n",
    "Вероятность каждого слова вычисляется на основе частоты встречаемости n-грамм в обучающем корпусе. В данном случае, поскольку n=3, модель учитывает последовательности из трёх слов. Для каждого слова в словаре модель вычисляет условную вероятность его появления после контекста.\n",
    "\n",
    "Слово с максимальной вероятностью выбирается как следующее слово.\n",
    "\n",
    "Это не обязательно самое популярное слово в корпусе, а скорее слово, которое наиболее вероятно появится в данном контексте на основе обучающих данных. Однако, если в обучающем корпусе есть слова, которые часто встречаются в контексте (\"word1\", \"word2\"), они будут иметь более высокую вероятность быть выбранными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2096fee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных\n",
    "texts = webtext.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c679a8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Cookie', 'Manager', ':', '\"', 'Don', \"'\", 't', 'allow', 'sites', 'that', 'set', 'removed', 'cookies', 'to', 'set', 'future', 'cookies', '\"', 'should', 'stay', 'checked', 'When', 'in', 'full', 'screen', 'mode', 'Pressing', 'Ctrl', '-', 'N', 'should', 'open', 'a', 'new', 'browser', 'when', 'only', 'download', 'dialog', 'is', 'left', 'open', 'add', 'icons', 'to', 'context', 'menu', 'So', 'called', '\"', 'tab', 'bar', '\"', 'should', 'be', 'made', 'a', 'proper', 'toolbar', 'or', 'given', 'the', 'ability', 'collapse', '/', 'expand', '.'], ['[', 'XUL', ']', 'Implement', 'Cocoa', '-', 'style', 'toolbar', 'customization', '.'], ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb9dd229",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94a9296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для предобработки текста\n",
    "def preprocess_sentence(sentence):\n",
    "    # Преобразование в нижний регистр\n",
    "    sentence = [word.lower() for word in sentence]\n",
    "    \n",
    "    # Удаление знаков препинания и стоп-слов\n",
    "    sentence = [word for word in sentence if word not in string.punctuation]\n",
    "    sentence = [word for word in sentence if word not in stop_words]\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b1b0cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_corpus(corpus):\n",
    "    return [preprocess_sentence(sentence) for sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a2e20cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка корпуса\n",
    "texts = preprocess_corpus(texts)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65e9c5be",
   "metadata": {},
   "source": [
    "В данном случае n=3, то есть это 3-gramm model. Она корректно работает, когда на вход подаются 2 слова. Если мы хотим предсказание после каждого слова, тогда нужно использовать биграммную модель. Но точность предсказания будет ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "90e78b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aff8685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLE(n) \n",
    "model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0b0f55ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = (\"add\",\"icons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ba2dad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_filter(model, num_words, context, random_seed):\n",
    "    return list(filter(lambda w: w != '</s>', model.generate(num_words, context, random_seed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "10728ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Следующие слова: ['urls', 'listed', 'location', 'bar', 'search']\n"
     ]
    }
   ],
   "source": [
    "print(\"Следующие слова:\", generate_and_filter(model, 5, context, random_seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e1cf027",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_counts = model.context_counts(model.vocab.lookup(context))\n",
    "sorted_words = sorted(context_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "top_5_words = [word for word, count in sorted_words[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "95b6f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_counts = model.context_counts(model.vocab.lookup(context))\n",
    "sorted_words = sorted(\n",
    "    ((word, count) for word, count in context_counts.items() if word != '</s>'),\n",
    "    key=lambda item: item[1],\n",
    "    reverse=True)\n",
    "top_5_words = [word for word, count in sorted_words[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "22931c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-5 следующих слов для заданного контекста: ['context', 'urls']\n"
     ]
    }
   ],
   "source": [
    "print(\"Топ-5 следующих слов для заданного контекста:\", top_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "68b0961b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Частота контекста в корпусе: 2\n"
     ]
    }
   ],
   "source": [
    "# Проверка наличия контекста в корпусе\n",
    "context_occurrences = sum(1 for sent in texts if context in zip(sent, sent[1:]))\n",
    "print(\"Частота контекста в корпусе:\", context_occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ee80acfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = (\"coffee\",\"shop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9f2da61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_filter(model, num_words, context, random_seed):\n",
    "    return list(filter(lambda w: w != '</s>', model.generate(num_words, context, random_seed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4ba6e12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Следующие слова: ['counter', 'guy', 'lady', 'manhattan']\n"
     ]
    }
   ],
   "source": [
    "print(\"Следующие слова:\", generate_and_filter(model, 5, context, random_seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf6cec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_counts = model.context_counts(model.vocab.lookup(context))\n",
    "sorted_words = sorted(\n",
    "    ((word, count) for word, count in context_counts.items() if word != '</s>'),\n",
    "    key=lambda item: item[1],\n",
    "    reverse=True)\n",
    "top_5_words = [word for word, count in sorted_words[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "abd198b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-5 следующих слов для заданного контекста: ['counter']\n"
     ]
    }
   ],
   "source": [
    "print(\"Топ-5 следующих слов для заданного контекста:\", top_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29f561e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Частота контекста в корпусе: 1\n"
     ]
    }
   ],
   "source": [
    "# Проверка наличия контекста в корпусе\n",
    "context_occurrences = sum(1 for sent in texts if context in zip(sent, sent[1:]))\n",
    "print(\"Частота контекста в корпусе:\", context_occurrences)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25eaf004",
   "metadata": {},
   "source": [
    "Биграммная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "284f565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "228be710",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLE(n) \n",
    "model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c7a1f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "context='restaurant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "39d01292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_filter(model, num_words, context, random_seed=42):\n",
    "    return list(filter(lambda w: w != '</s>', model.generate(num_words, context, random_seed=42)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "698baf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Следующие слова: ['liquorice', 'always', 'easy', 'pick']\n"
     ]
    }
   ],
   "source": [
    "print(\"Следующие слова:\", generate_and_filter(model, 5, context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "447ed129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для получения топ-5 слов для заданного контекста\n",
    "def get_top_5_next_words(model, context):\n",
    "    # Получаем словарь вероятностей для всех слов, следующих за контекстом\n",
    "    context = [context]\n",
    "    candidates = model.context_counts(model.vocab.lookup(context))\n",
    "    # Сортируем по вероятности и берем топ-5\n",
    "    top_5 = sorted(((word, count) for word, count in candidates.items() if word != '</s>'), key=lambda item: item[1], reverse=True)[:5]\n",
    "    return [word for word, count in top_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "24e3f39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-5 слов после 'restaurant': ['guy', 'half', 'talking', 'eat', 'everyone']\n"
     ]
    }
   ],
   "source": [
    "# Пример использования\n",
    " # пример слова-контекста\n",
    "top_5_words = get_top_5_next_words(model, context)\n",
    "print(f\"Топ-5 слов после '{context}': {top_5_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c447d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
